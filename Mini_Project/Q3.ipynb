{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector1H(x, maxInd):\n",
    "    out = np.zeros(maxInd)\n",
    "    out[x-1] = 1\n",
    "    return out\n",
    "\n",
    "def mat1H(x, maxInd):\n",
    "    out = np.zeros((x.shape[0], x.shape[1], maxInd))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            out[i,j,:] = vector1H(x[i,j], maxInd)\n",
    "    return out\n",
    "\n",
    "def mat1H2(y, maxInd):\n",
    "    out = np.zeros((y.shape[0], maxInd))\n",
    "    for i in range(y.shape[0]):\n",
    "        out[i,:] = vector1H(y[i], maxInd)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['testd', 'testx', 'traind', 'trainx', 'vald', 'valx', 'words']>\n"
     ]
    }
   ],
   "source": [
    "filename = 'data2.h5'\n",
    "\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    # Get the data\n",
    "    test_labels = f[list(f.keys())[0]][:]\n",
    "    test_data = f[list(f.keys())[1]][:]\n",
    "    train_labels = f[list(f.keys())[2]][:]\n",
    "    train_data = f[list(f.keys())[3]][:]\n",
    "    val_labels = f[list(f.keys())[4]][:]\n",
    "    val_data = f[list(f.keys())[5]][:]\n",
    "    wordDict = f[list(f.keys())[6]][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(inputDim,numNeurons,activation,std,mean=0):\n",
    "    if activation == \"sigmoid\" or activation == \"softmax\":\n",
    "        w = np.random.normal(mean,std, inputDim*numNeurons).reshape(numNeurons, inputDim)\n",
    "        b = np.random.normal(mean,std, numNeurons).reshape(numNeurons,1)\n",
    "        weights = np.concatenate((w, b), axis=1)\n",
    "    elif activation == 'we':\n",
    "        weights = np.random.normal(mean, std, numNeurons*inputDim).reshape((numNeurons,inputDim))\n",
    "    return weights\n",
    "\n",
    "def select_activation(x,activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    elif actiavation == \"softmax\":\n",
    "        expx = np.exp(x - np.max(x))\n",
    "        y = expx/np.sum(expx, axis=0)\n",
    "        return y\n",
    "    elif actiavation == \"we\":\n",
    "        return x\n",
    "    \n",
    "def activation_backward(x):\n",
    "    if activation == \"sigmoid\":\n",
    "        return 2*(x*(1-x))\n",
    "    elif actiavation == \"softmax\":\n",
    "        return x*(1-x)\n",
    "    elif actiavation == \"we\":\n",
    "        return np.ones(x.shape)\n",
    "\n",
    "def activate_layer(x,activation,weights):\n",
    "    if activation == \"sigmoid\" or activation == \"softmax\":\n",
    "        if(x.ndim == 1):\n",
    "                x = x.reshape(x.shape[0],1)\n",
    "        numSamples = x.shape[1]\n",
    "        tempInp = np.r_[x, [np.ones(numSamples)*-1]]\n",
    "        print(tempInp.shape)\n",
    "        lastActiv = select_activation(np.matmul(weights, tempInp),activation)        \n",
    "        \n",
    "    elif activation == 'we':\n",
    "        layerOut = np.zeros((x.shape[0],x.shape[1], 250))\n",
    "        for m in range(layerOut.shape[0]):\n",
    "            layerOut[m,:,:] = select_activation(np.matmul(x[m,:,:], weights),activation)\n",
    "        layerOut = layerOut.reshape((layerOut.shape[0], layerOut.shape[1] * layerOut.shape[2]))\n",
    "        lastActiv = layerOut.T\n",
    "        return lastActiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 33)\n"
     ]
    }
   ],
   "source": [
    "weightsE = initialize_weights(32,250,\"softmax\",0.01)\n",
    "print(weightsE.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, inputDim, numNeurons, activation, std, mean=0):\n",
    "        self.inputDim = inputDim\n",
    "        self.numNeurons = numNeurons\n",
    "        self.activation = activation\n",
    "        if self.activation == 'sigmoid' or self.activation == 'softmax':\n",
    "            self.weights = np.random.normal(mean,std, inputDim*numNeurons).reshape(numNeurons, inputDim)\n",
    "            self.biases = np.random.normal(mean,std, numNeurons).reshape(numNeurons,1)\n",
    "            self.weightsE = np.concatenate((self.weights, self.biases), axis=1)\n",
    "        elif self.activation == 'we':\n",
    "            self.dictSize = numNeurons\n",
    "            self.D = inputDim\n",
    "            self.weights = np.random.normal(mean, std, dictSize*D).reshape((dictSize,D))\n",
    "            \n",
    "        \n",
    "        self.delta = None\n",
    "        self.error = None\n",
    "        self.lastActiv = None\n",
    "        \n",
    "        self.prevUpdate = 0\n",
    "        \n",
    "        \n",
    "    def actFcn(self,x):\n",
    "        if(self.activation == 'sigmoid'):\n",
    "            expx = np.exp(2*x)\n",
    "            return expx/(1+expx)\n",
    "        elif(self.activation == 'softmax'):\n",
    "            expx = np.exp(x - np.max(x))\n",
    "            return expx/np.sum(expx, axis=0)\n",
    "        elif(self.activation == 'we'):\n",
    "            return x\n",
    "                    \n",
    "    def activate(self, x):\n",
    "        if self.activation == 'sigmoid' or self.activation == 'softmax':\n",
    "            if(x.ndim == 1):\n",
    "                x = x.reshape(x.shape[0],1)\n",
    "            numSamples = x.shape[1]\n",
    "            tempInp = np.r_[x, [np.ones(numSamples)*-1]]\n",
    "            \n",
    "            #print('hLayerW', self.weights.shape)\n",
    "            #print('hLayerInp', tempInp.shape)\n",
    "            \n",
    "            self.lastActiv = self.actFcn(np.matmul(self.weightsE, tempInp))\n",
    "        elif self.activation == 'we':\n",
    "            #print('x: \\n', x, x.shape)\n",
    "            #print('w: \\n', self.weights, self.weights.shape)\n",
    "            layerOut = np.zeros((x.shape[0],x.shape[1], self.D))\n",
    "            for m in range(layerOut.shape[0]):\n",
    "                layerOut[m,:,:] = self.actFcn(np.matmul(x[m,:,:], self.weights))\n",
    "            layerOut = layerOut.reshape((layerOut.shape[0], layerOut.shape[1] * layerOut.shape[2]))\n",
    "            self.lastActiv = layerOut.T\n",
    "            #print('weOut', layerOut.shape)\n",
    "        return self.lastActiv\n",
    "    \n",
    "    def derActiv(self, x):\n",
    "        if(self.activation == 'sigmoid'):\n",
    "            return 2*(x*(1-x))\n",
    "        elif(self.activation == 'softmax'):\n",
    "            return x*(1-x)\n",
    "        elif(self.activation == 'we'):\n",
    "            return np.ones(x.shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Input Dim: \" + str(self.inputDim) + \", Number of Neurons: \" + str(self.numNeurons) + \"\\n Activation: \" + self.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordNet:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        \n",
    "    def addLayer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        out = inp\n",
    "        for lyr in self.layers:\n",
    "            out = lyr.activate(out)\n",
    "        return out\n",
    "    \n",
    "    def prediction(self, inp):\n",
    "        out = self.forward(inp)\n",
    "        if(out.ndim == 1):\n",
    "            return np.argmax(out)\n",
    "        return np.argmax(out, axis=0)\n",
    "    \n",
    "    def predictionTopK(self, inp, k):\n",
    "        out = self.forward(inp)\n",
    "        #print(out)\n",
    "        return np.argpartition(out, -k, axis=0)[-k:]\n",
    "        \n",
    "    \n",
    "    def backProp(self, inp, out, lrnRate, momCoeff, batchSize):\n",
    "        net_out = self.forward(inp)\n",
    "        #print('network out: ', net_out.shape)\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            lyr = self.layers[i]\n",
    "            #outputLayer\n",
    "            if(lyr == self.layers[-1]):\n",
    "                lyr.delta = out - net_out\n",
    "            #hiddenLayer\n",
    "            else:\n",
    "                nextLyr = self.layers[i+1]\n",
    "                nextLyr.weights = nextLyr.weightsE[:,0:nextLyr.weights.shape[1]]\n",
    "                lyr.error = np.matmul(nextLyr.weights.T, nextLyr.delta)\n",
    "                derMatrix = lyr.derActiv(lyr.lastActiv)\n",
    "                lyr.delta = derMatrix * lyr.error\n",
    "        \n",
    "        #update weights\n",
    "        for i in range(len(self.layers)):\n",
    "            lyr = self.layers[i]\n",
    "            #write dynamic if later\n",
    "            if(i == 0):\n",
    "                if(inp.ndim == 1):\n",
    "                    inp = inp.reshape(inp.shape[0],1)\n",
    "                numSamples = inp.shape[1]\n",
    "                inputToUse = inp\n",
    "            else:\n",
    "                numSamples = self.layers[i - 1].lastActiv.shape[1]\n",
    "                inputToUse = np.r_[self.layers[i - 1].lastActiv, [np.ones(numSamples)*-1]]\n",
    "            #print('delta of layer[' + str(i) + ']', lyr.delta.shape)\n",
    "            #print('inputToUse.T of layer[' + str(i) + ']', inputToUse.T.shape)\n",
    "            if(lyr.activation == 'sigmoid' or lyr.activation == 'softmax'):\n",
    "                update =  (lrnRate * np.matmul(lyr.delta, inputToUse.T))/batchSize\n",
    "                lyr.weightsE += update + momCoeff * lyr.prevUpdate\n",
    "            elif(lyr.activation == 'we'):\n",
    "                delta3d = lyr.delta.reshape((3,batchSize,lyr.D))\n",
    "                inputToUse = np.transpose(inputToUse, (1,2,0))\n",
    "                update = np.zeros((inputToUse.shape[1], delta3d.shape[2]))\n",
    "                for i in range(delta3d.shape[0]):\n",
    "                    update += lrnRate * np.matmul(inputToUse[i,:,:], delta3d[i,:,:])\n",
    "                #mean the updates for each separate word\n",
    "                #update = update/delta3d.shape[0]\n",
    "                update = update/batchSize\n",
    "                lyr.weights += update + momCoeff * lyr.prevUpdate\n",
    "            lyr.prevUpdate = update\n",
    "            \n",
    "    def train(self, inp, out, inpTest, outTest, lrnRate, momCoeff, epochNum, batchSize):\n",
    "        cveList = []\n",
    "        \n",
    "        for ep in range(epochNum):\n",
    "            print('Epoch', ep)\n",
    "            \n",
    "            randomIndexes = np.random.permutation(len(inp))\n",
    "            inp = inp[randomIndexes]\n",
    "            out = out[randomIndexes]\n",
    "            numBatches = int(np.floor(len(inp)/batchSize))\n",
    "            \n",
    "            for j in range(numBatches):\n",
    "                batch_inp = inp[batchSize*j:batchSize*j+batchSize]\n",
    "                batch_out = out[batchSize*j:batchSize*j+batchSize]\n",
    "                \n",
    "                batch_inp_1H = mat1H(batch_inp, dictSize)\n",
    "                batch_out_1H = mat1H2(batch_out, dictSize).T\n",
    "                \n",
    "                self.backProp(batch_inp_1H, batch_out_1H, lrnRate, momCoeff, batchSize)\n",
    "            \n",
    "            valOutput = self.forward(inpTest)\n",
    "            #print('Prediction Probs \\n', valOutput)\n",
    "            #print('Test \\n', outTest)\n",
    "            \n",
    "            crossErr = - np.sum(np.log(valOutput) * outTest.T)/valOutput.shape[1]\n",
    "            print('Cross-Entropy Error ', crossErr)\n",
    "            cveList.append(crossErr)\n",
    "            \n",
    "            valAcc = np.sum(self.prediction(inpTest) == np.argmax(outTest.T, axis=0))\n",
    "            print('Correct: ', valAcc)\n",
    "            print('Accuracy: ', valAcc/valOutput.shape[1])\n",
    "                \n",
    "        return cveList\n",
    "    \n",
    "    def __repr__(self):\n",
    "        retStr = \"\"\n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            retStr += \"Layer \" + str(i) + \": \" + lyr.__repr__() + \"\\n\"\n",
    "        return retStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dim: 32, Number of Neurons: 250\n",
      " Activation: we\n"
     ]
    }
   ],
   "source": [
    "P = 256\n",
    "D = 32\n",
    "dictSize = 250\n",
    "\n",
    "print(Layer(D, dictSize, 'we', 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Cross-Entropy Error  3.4755334712386245\n",
      "Correct:  12750\n",
      "Accuracy:  0.27419354838709675\n",
      "Epoch 1\n",
      "Cross-Entropy Error  3.3098787618544874\n",
      "Correct:  13570\n",
      "Accuracy:  0.2918279569892473\n",
      "Epoch 2\n",
      "Cross-Entropy Error  3.214277212529971\n",
      "Correct:  14053\n",
      "Accuracy:  0.3022150537634409\n",
      "Epoch 3\n",
      "Cross-Entropy Error  3.1372798137116815\n",
      "Correct:  14505\n",
      "Accuracy:  0.31193548387096776\n",
      "Epoch 4\n",
      "Cross-Entropy Error  3.0832075305528854\n",
      "Correct:  14782\n",
      "Accuracy:  0.31789247311827956\n",
      "Epoch 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5m/wtqy79094gngztxy0mc58b100000gn/T/ipykernel_34787/4205391701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m errors = nn.train(train_data, train_labels, val_inp_1H, val_labels_1H,\\\n\u001b[1;32m     19\u001b[0m                   \u001b[0mlearnRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomCoeff\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                   epoch, batchSize)\n\u001b[0m",
      "\u001b[0;32m/var/folders/5m/wtqy79094gngztxy0mc58b100000gn/T/ipykernel_34787/101539941.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inp, out, inpTest, outTest, lrnRate, momCoeff, epochNum, batchSize)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mbatch_out_1H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat1H2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inp_1H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_out_1H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrnRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomCoeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mvalOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5m/wtqy79094gngztxy0mc58b100000gn/T/ipykernel_34787/101539941.py\u001b[0m in \u001b[0;36mbackProp\u001b[0;34m(self, inp, out, lrnRate, momCoeff, batchSize)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrnRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomCoeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print('network out: ', net_out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5m/wtqy79094gngztxy0mc58b100000gn/T/ipykernel_34787/101539941.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlyr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5m/wtqy79094gngztxy0mc58b100000gn/T/ipykernel_34787/2472725669.py\u001b[0m in \u001b[0;36mactivate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mlayerOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mlayerOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactFcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mlayerOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastActiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayerOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "P = 256\n",
    "D = 32\n",
    "dictSize = 250\n",
    "\n",
    "nn = WordNet()\n",
    "nn.addLayer(Layer(D, dictSize, 'we', 0.2))\n",
    "nn.addLayer(Layer(3*D, P, 'sigmoid', 0.2))\n",
    "nn.addLayer(Layer(P, dictSize, 'softmax', 0.2))\n",
    "\n",
    "learnRate = 0.35\n",
    "momCoeff = 0.85\n",
    "batchSize = 250\n",
    "epoch = 50\n",
    "\n",
    "val_inp_1H = mat1H(val_data, dictSize)\n",
    "val_labels_1H = mat1H2(val_labels, dictSize)\n",
    "\n",
    "errors = nn.train(train_data, train_labels, val_inp_1H, val_labels_1H,\\\n",
    "                  learnRate, momCoeff,\\\n",
    "                  epoch, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errors)\n",
    "plt.title('Cross-Entropy Error over Validation Set')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[241 201  43  73 109]\n",
      " [198 210 104 154 178]\n",
      " [ 58 213 139 191  41]\n",
      " [155  22  27  22 189]\n",
      " [106  73  58 166  31]\n",
      " [ 45 157  71  88  50]\n",
      " [ 22 230 198 157 182]\n",
      " [ 88 203 175 173 183]\n",
      " [143 143  95 143 199]\n",
      " [190  57 200 192  67]]\n",
      "[1] long, time, ago\n",
      "The Top-K predictions are: {i, at, right, ago, last, now, ,, ?, ., then, }\n",
      "[2] do, nt, know\n",
      "The Top-K predictions are: {any, when, how, ,, what, that, who, if, ., where, }\n",
      "[3] see, who, 's\n",
      "The Top-K predictions are: {not, on, there, going, right, out, at, up, here, in, }\n",
      "[4] want, to, do\n",
      "The Top-K predictions are: {what, more, is, ,, with, ?, that, this, ., it, }\n",
      "[5] one, day, we\n",
      "The Top-K predictions are: {could, will, know, have, do, did, can, were, want, are, }\n"
     ]
    }
   ],
   "source": [
    "num_samples = 5\n",
    "\n",
    "random_sample_indexes = np.random.permutation(len(test_data))[0:num_samples]\n",
    "\n",
    "test_samples = test_data[random_sample_indexes]\n",
    "test_outputs = test_labels[random_sample_indexes]\n",
    "\n",
    "test_samples_1H = mat1H(test_samples, dictSize)\n",
    "test_labels_1H = mat1H2(test_outputs, dictSize)\n",
    "\n",
    "top10predictions = nn.predictionTopK(test_samples_1H, 10)\n",
    "\n",
    "print(top10predictions)\n",
    "\n",
    "for i in range(num_samples):\n",
    "    print('[' + str(i+1) + '] ' + str(wordDict[test_samples[i,0]-1].decode(\"utf-8\"))  + ', ' + \\\n",
    "          str(wordDict[test_samples[i,1]-1].decode(\"utf-8\")) \\\n",
    "          + ', ' + str(wordDict[test_samples[i,2]-1].decode(\"utf-8\")))\n",
    "    strin = 'The Top-K predictions are: {'\n",
    "    for j in range(10):\n",
    "        strin += (str(wordDict[top10predictions[j,i]].decode(\"utf-8\"))) + ', '\n",
    "    print(strin + '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_index(sample_size):\n",
    "    random_index = []\n",
    "    for i in range(sample_size):\n",
    "        index = random.randint(0,46500)\n",
    "        random_index.append(index)\n",
    "    return random_index\n",
    "\n",
    "def pick_sample(data,label,sample_size):\n",
    "    sample = []\n",
    "    labels = []\n",
    "    sample_index = random_index(sample_size)\n",
    "    for i in sample_index:\n",
    "        sample.append(data[i])\n",
    "        labels.append(label[i])\n",
    "    return sample,labels\n",
    "\n",
    "def predict(words,output):\n",
    "    pred_rows = []\n",
    "    for i in range(len(output)):\n",
    "        word_index = output[i].argsort()[-10:][::-1]\n",
    "        pred_words = []\n",
    "        for word in word_index: \n",
    "            pred_words.append(str(words[word].decode(\"utf-8\")))\n",
    "        pred_rows.append((pred_words))\n",
    "    return pred_rows\n",
    "\n",
    "def print_preds(random_sample,pred_rows,words):\n",
    "    for i in range(len(random_sample)):\n",
    "        tri = \"sample trigram: \"\n",
    "        for j in range(len(random_sample[i])):\n",
    "            tri+=str(words[random_sample[i][j]].decode(\"utf-8\"))+\" \"\n",
    "        tri += \" ----> label: \" + str(words[test_label[i]].decode(\"utf-8\"))\n",
    "        print(tri)\n",
    "        print(\"Top 10 predictions: \",pred_rows[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample,test_label = pick_sample(x_test,y_test,200)\n",
    "random_sample_vector = input_vector(random_sample)\n",
    "random_sample_vector = np.squeeze(random_sample_vector,axis=1)\n",
    "random_sample = random_sample[:5]\n",
    "test_label  = test_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,output = forward(random_sample_vector, we)\n",
    "output = output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rows = predict(words,output)\n",
    "print_preds(random_sample,pred_rows,words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
